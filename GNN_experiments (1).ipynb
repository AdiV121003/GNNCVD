{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VivcbzbdWXKs"
      },
      "source": [
        "This notebook shows the steps of extracting ASTs, building the dataset on Pytorch Geometric and then applying GNN model for graph embedding as well as predicting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPOHae26WmSy",
        "outputId": "7ec0b465-baa0-40fc-caa9-6c2de8faa762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.11)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2024.12.14)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjdV4fUCWXKx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
        "    accuracy_score, precision_score, recall_score\n",
        "from torch_geometric.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qwWMqLqWXKy"
      },
      "outputs": [],
      "source": [
        "import clang.cindex\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "rc('font',**{'family':'serif','serif':['Palatino'], 'size'   : 24})\n",
        "rc('text', usetex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAEPZsQOWXKy"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.font_manager as fm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9qt_OIsWXKy"
      },
      "source": [
        "Uploading a processed CWE type:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V968it18WXKz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "8891348e-ca84-408a-eb14-7a4f3e8af3d7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/vdisc_CWE_469.csv.gz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-df2d5801597e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvdisc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/vdisc_CWE_469.csv.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvdisc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bug\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvdisc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bug\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    763\u001b[0m                 \u001b[0;31m# error: Incompatible types in assignment (expression has type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                 \u001b[0;31m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                 handle = gzip.GzipFile(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m    766\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/vdisc_CWE_469.csv.gz'"
          ]
        }
      ],
      "source": [
        "vdisc = pd.read_csv(\"/content/vdisc_CWE_469.csv.gz\")\n",
        "vdisc[\"bug\"] = vdisc[\"bug\"].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "SNvXH-EjWXK0",
        "outputId": "6067129d-c198-4a1d-ac1e-ea370d06fc1d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DatasetDict' object has no attribute 'info'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-47dbfccc1270>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'info'"
          ]
        }
      ],
      "source": [
        "vdisc.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5-jqiCgWXK0"
      },
      "source": [
        "Extracting AST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E1Z6LVSWXK0"
      },
      "outputs": [],
      "source": [
        "def save_ast(node):\n",
        "\n",
        "    node.children = list(node.get_children())\n",
        "\n",
        "    for child in node.children:\n",
        "        counter = save_ast(child)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWnSBoxxWXK0"
      },
      "outputs": [],
      "source": [
        "def numbering_ast_nodes(node, counter=1):\n",
        "\n",
        "    node.identifier = counter\n",
        "    counter += 1\n",
        "\n",
        "    node.children = list(node.get_children())\n",
        "    for child in node.children:\n",
        "        counter = numbering_ast_nodes(child, counter)\n",
        "\n",
        "    return counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C5l72X5WXK1"
      },
      "outputs": [],
      "source": [
        "def generate_edgelist(ast_root):\n",
        "\n",
        "    edges = [[],[]]\n",
        "\n",
        "    def walk_tree_and_add_edges(node):\n",
        "        for child in node.children:\n",
        "            # edges.append([node.identifier, child.identifier])\n",
        "            # walk_tree_and_add_edges(child)\n",
        "            edg_0 = (node.identifier)-1\n",
        "            edg_1 = (child.identifier)-1\n",
        "            # edges[0].append(node.identifier)\n",
        "            # edges[1].append(child.identifier)\n",
        "            edges[0].append(edg_0)\n",
        "            edges[1].append(edg_1)\n",
        "            walk_tree_and_add_edges(child)\n",
        "\n",
        "    walk_tree_and_add_edges(ast_root)\n",
        "    return  torch.tensor(edges, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRV_tAtyWXK1"
      },
      "outputs": [],
      "source": [
        "def generate_features(ast_root):\n",
        "\n",
        "    features = []\n",
        "\n",
        "    def walk_tree_and_set_features(node):\n",
        "        out_degree = len(node.children)\n",
        "        #in_degree = 1\n",
        "        #degree = out_degree + in_degree\n",
        "        degree = out_degree\n",
        "        node_id = node.identifier\n",
        "        features.append([node_id, degree])\n",
        "\n",
        "        for child in node.children:\n",
        "            walk_tree_and_set_features(child)\n",
        "\n",
        "    walk_tree_and_set_features(ast_root)\n",
        "\n",
        "    features_array = np.asarray(features)\n",
        "    # nodes_tensor = torch.from_numpy(features_array).float()\n",
        "    nodes_tensor = torch.tensor(features_array, dtype=torch.float)\n",
        "    # nodes_tensor = torch.LongTensor(features).unsqueeze(1)\n",
        "    return nodes_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJm-5xVsWXK1"
      },
      "outputs": [],
      "source": [
        "def clang_process(testcase, **kwargs):\n",
        "\n",
        "    parse_list = [\n",
        "        (testcase.filename, testcase.code)\n",
        "\n",
        "    ]\n",
        "\n",
        "    # source_file= get_source_file(testcase)\n",
        "\n",
        "    # Parsing the source code and extracting AST using clang\n",
        "    index = clang.cindex.Index.create()\n",
        "    translation_unit = index.parse(\n",
        "        path=testcase.filename,\n",
        "        unsaved_files=parse_list,\n",
        "    )\n",
        "    ast_root = translation_unit.cursor\n",
        "\n",
        "    save_ast(ast_root)\n",
        "    numbering_ast_nodes(ast_root)\n",
        "\n",
        "    graphs_embedding = generate_edgelist(ast_root)\n",
        "\n",
        "    nodes_embedding = generate_features(ast_root)\n",
        "\n",
        "\n",
        "    y = torch.tensor([testcase.bug], dtype=torch.int64)\n",
        "\n",
        "\n",
        "\n",
        "    # delete clang objects\n",
        "    del translation_unit\n",
        "    del ast_root\n",
        "    del index\n",
        "\n",
        "    return Data(x=nodes_embedding, edge_index=graphs_embedding, y=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOSs0aLQWXK1"
      },
      "source": [
        "Building the dataset on Pytorch geometrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIusGFvVWXK1"
      },
      "outputs": [],
      "source": [
        "class MyOwnDataset(Dataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return []\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'not_implemented.pt'\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        self.data = pd.read_csv(\"/content/vdisc_CWE_469.csv.gz\")\n",
        "        for index, vuln in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
        "            data = clang_process(vuln)\n",
        "            torch.save(data, os.path.join(self.processed_dir, f'data_{index}.pt'))\n",
        "\n",
        "    def len(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(os.path.join(self.processed_dir,\n",
        "                                 f'data_{idx}.pt'))\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57TQ4M7OWXK2",
        "outputId": "31a3d978-7c58-406b-875c-eebf42b842ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "100%|██████████| 5250/5250 [00:32<00:00, 161.87it/s]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset = MyOwnDataset(root='/content/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_PjNuB2WXK2",
        "outputId": "f8aa6b53-4791-4490-f566-02530ac96652"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5250"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNfOSzixWXK2",
        "outputId": "cb210ad5-367d-4ab2-b4f5-dc6d526d053d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of features: {dataset.num_features}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9ytnWglWXK2",
        "outputId": "c21360ab-d62b-4a0a-c128-08bb573a6049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 115\n",
            "Number of edges: 114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        }
      ],
      "source": [
        "data1 = dataset[2]  # Get the first graph object.\n",
        "print(f'Number of nodes: {data1.num_nodes}')\n",
        "print(f'Number of edges: {data1.num_edges}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "owU6O1-bWXK3",
        "outputId": "0b403d7d-cc12-4eab-d614-b06f23cb4b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0,   1],\n",
            "        [  1,   2],\n",
            "        [  2,   3],\n",
            "        [  1,   4],\n",
            "        [  4,   5],\n",
            "        [  1,   6],\n",
            "        [  6,   7],\n",
            "        [  7,   8],\n",
            "        [  7,   9],\n",
            "        [  9,  10],\n",
            "        [  6,  11],\n",
            "        [ 11,  12],\n",
            "        [ 11,  13],\n",
            "        [ 13,  14],\n",
            "        [ 14,  15],\n",
            "        [ 15,  16],\n",
            "        [  6,  17],\n",
            "        [ 17,  18],\n",
            "        [ 18,  19],\n",
            "        [ 19,  20],\n",
            "        [ 19,  21],\n",
            "        [ 21,  22],\n",
            "        [ 19,  23],\n",
            "        [ 18,  24],\n",
            "        [ 17,  25],\n",
            "        [  6,  26],\n",
            "        [ 26,  27],\n",
            "        [ 27,  28],\n",
            "        [ 26,  29],\n",
            "        [ 29,  30],\n",
            "        [ 29,  31],\n",
            "        [ 31,  32],\n",
            "        [  6,  33],\n",
            "        [ 33,  34],\n",
            "        [ 33,  35],\n",
            "        [ 35,  36],\n",
            "        [ 36,  37],\n",
            "        [ 36,  38],\n",
            "        [ 36,  39],\n",
            "        [ 36,  40],\n",
            "        [ 40,  41],\n",
            "        [  6,  42],\n",
            "        [ 42,  43],\n",
            "        [ 43,  44],\n",
            "        [ 44,  45],\n",
            "        [ 44,  46],\n",
            "        [ 46,  47],\n",
            "        [ 44,  48],\n",
            "        [ 43,  49],\n",
            "        [ 42,  50],\n",
            "        [ 50,  51],\n",
            "        [ 50,  52],\n",
            "        [ 50,  53],\n",
            "        [ 53,  54],\n",
            "        [ 53,  55],\n",
            "        [ 55,  56],\n",
            "        [ 42,  57],\n",
            "        [ 57,  58],\n",
            "        [ 58,  59],\n",
            "        [ 59,  60],\n",
            "        [ 59,  61],\n",
            "        [ 61,  62],\n",
            "        [ 59,  63],\n",
            "        [ 58,  64],\n",
            "        [ 57,  65],\n",
            "        [ 65,  66],\n",
            "        [ 65,  67],\n",
            "        [ 65,  68],\n",
            "        [ 68,  69],\n",
            "        [ 57,  70],\n",
            "        [ 70,  71],\n",
            "        [ 71,  72],\n",
            "        [ 72,  73],\n",
            "        [ 72,  74],\n",
            "        [ 74,  75],\n",
            "        [ 72,  76],\n",
            "        [ 71,  77],\n",
            "        [ 70,  78],\n",
            "        [ 78,  79],\n",
            "        [ 78,  80],\n",
            "        [ 78,  81],\n",
            "        [ 81,  82],\n",
            "        [ 81,  83],\n",
            "        [ 83,  84],\n",
            "        [ 70,  85],\n",
            "        [ 85,  86],\n",
            "        [ 86,  87],\n",
            "        [ 87,  88],\n",
            "        [ 87,  89],\n",
            "        [ 89,  90],\n",
            "        [ 87,  91],\n",
            "        [ 86,  92],\n",
            "        [ 85,  93],\n",
            "        [ 93,  94],\n",
            "        [ 93,  95],\n",
            "        [ 93,  96],\n",
            "        [ 96,  97],\n",
            "        [ 96,  98],\n",
            "        [ 98,  99],\n",
            "        [ 85, 100],\n",
            "        [100, 101],\n",
            "        [101, 102],\n",
            "        [102, 103],\n",
            "        [102, 104],\n",
            "        [104, 105],\n",
            "        [102, 106],\n",
            "        [101, 107],\n",
            "        [100, 108],\n",
            "        [108, 109],\n",
            "        [108, 110],\n",
            "        [108, 111],\n",
            "        [111, 112],\n",
            "        [111, 113],\n",
            "        [113, 114]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        }
      ],
      "source": [
        "print(dataset[2].edge_index.t())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vJr20ZlqWXK3",
        "outputId": "295e47d2-5977-47f7-8800-1ff5d7339df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1.,   1.],\n",
            "        [  2.,   3.],\n",
            "        [  3.,   1.],\n",
            "        [  4.,   0.],\n",
            "        [  5.,   1.],\n",
            "        [  6.,   0.],\n",
            "        [  7.,   6.],\n",
            "        [  8.,   2.],\n",
            "        [  9.,   0.],\n",
            "        [ 10.,   1.],\n",
            "        [ 11.,   0.],\n",
            "        [ 12.,   2.],\n",
            "        [ 13.,   0.],\n",
            "        [ 14.,   1.],\n",
            "        [ 15.,   1.],\n",
            "        [ 16.,   1.],\n",
            "        [ 17.,   0.],\n",
            "        [ 18.,   2.],\n",
            "        [ 19.,   2.],\n",
            "        [ 20.,   3.],\n",
            "        [ 21.,   0.],\n",
            "        [ 22.,   1.],\n",
            "        [ 23.,   0.],\n",
            "        [ 24.,   0.],\n",
            "        [ 25.,   0.],\n",
            "        [ 26.,   0.],\n",
            "        [ 27.,   2.],\n",
            "        [ 28.,   1.],\n",
            "        [ 29.,   0.],\n",
            "        [ 30.,   2.],\n",
            "        [ 31.,   0.],\n",
            "        [ 32.,   1.],\n",
            "        [ 33.,   0.],\n",
            "        [ 34.,   2.],\n",
            "        [ 35.,   0.],\n",
            "        [ 36.,   1.],\n",
            "        [ 37.,   4.],\n",
            "        [ 38.,   0.],\n",
            "        [ 39.,   0.],\n",
            "        [ 40.,   0.],\n",
            "        [ 41.,   1.],\n",
            "        [ 42.,   0.],\n",
            "        [ 43.,   3.],\n",
            "        [ 44.,   2.],\n",
            "        [ 45.,   3.],\n",
            "        [ 46.,   0.],\n",
            "        [ 47.,   1.],\n",
            "        [ 48.,   0.],\n",
            "        [ 49.,   0.],\n",
            "        [ 50.,   0.],\n",
            "        [ 51.,   3.],\n",
            "        [ 52.,   0.],\n",
            "        [ 53.,   0.],\n",
            "        [ 54.,   2.],\n",
            "        [ 55.,   0.],\n",
            "        [ 56.,   1.],\n",
            "        [ 57.,   0.],\n",
            "        [ 58.,   3.],\n",
            "        [ 59.,   2.],\n",
            "        [ 60.,   3.],\n",
            "        [ 61.,   0.],\n",
            "        [ 62.,   1.],\n",
            "        [ 63.,   0.],\n",
            "        [ 64.,   0.],\n",
            "        [ 65.,   0.],\n",
            "        [ 66.,   3.],\n",
            "        [ 67.,   0.],\n",
            "        [ 68.,   0.],\n",
            "        [ 69.,   1.],\n",
            "        [ 70.,   0.],\n",
            "        [ 71.,   3.],\n",
            "        [ 72.,   2.],\n",
            "        [ 73.,   3.],\n",
            "        [ 74.,   0.],\n",
            "        [ 75.,   1.],\n",
            "        [ 76.,   0.],\n",
            "        [ 77.,   0.],\n",
            "        [ 78.,   0.],\n",
            "        [ 79.,   3.],\n",
            "        [ 80.,   0.],\n",
            "        [ 81.,   0.],\n",
            "        [ 82.,   2.],\n",
            "        [ 83.,   0.],\n",
            "        [ 84.,   1.],\n",
            "        [ 85.,   0.],\n",
            "        [ 86.,   3.],\n",
            "        [ 87.,   2.],\n",
            "        [ 88.,   3.],\n",
            "        [ 89.,   0.],\n",
            "        [ 90.,   1.],\n",
            "        [ 91.,   0.],\n",
            "        [ 92.,   0.],\n",
            "        [ 93.,   0.],\n",
            "        [ 94.,   3.],\n",
            "        [ 95.,   0.],\n",
            "        [ 96.,   0.],\n",
            "        [ 97.,   2.],\n",
            "        [ 98.,   0.],\n",
            "        [ 99.,   1.],\n",
            "        [100.,   0.],\n",
            "        [101.,   2.],\n",
            "        [102.,   2.],\n",
            "        [103.,   3.],\n",
            "        [104.,   0.],\n",
            "        [105.,   1.],\n",
            "        [106.,   0.],\n",
            "        [107.,   0.],\n",
            "        [108.,   0.],\n",
            "        [109.,   3.],\n",
            "        [110.,   0.],\n",
            "        [111.,   0.],\n",
            "        [112.,   2.],\n",
            "        [113.,   0.],\n",
            "        [114.,   1.],\n",
            "        [115.,   0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        }
      ],
      "source": [
        "print(dataset[2].x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_y2Mjk-WXK3",
        "outputId": "b6a50e35-b453-4924-aaec-9c249e8726e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        }
      ],
      "source": [
        "print(dataset[2].y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhkRkIrIWXK4"
      },
      "source": [
        "Split up the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUwUSFXGWXK4",
        "outputId": "0c8f4b3e-81b6-43a1-c0d5-994712286def"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4200, 525, 525)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dataset = dataset.shuffle()\n",
        "#one_tenth_length = int(len(dataset) * 0.1)\n",
        "one_tenth_length = int(len(dataset) * 0.1)\n",
        "train_dataset = dataset[:one_tenth_length * 8]\n",
        "val_dataset = dataset[one_tenth_length*8:one_tenth_length * 9]\n",
        "test_dataset = dataset[one_tenth_length*9:]\n",
        "#test_dataset = dataset[one_tenth_length*8:one_tenth_length * 10]\n",
        "len(train_dataset), len(val_dataset), len(test_dataset)\n",
        "#len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwGPz3qUWXK4",
        "outputId": "e2ebbaf8-5283-411c-c882-3925e4e72fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "NUM_GRAPHS_PER_BATCH = 256\n",
        "train_loader = DataLoader(train_dataset, batch_size=NUM_GRAPHS_PER_BATCH,drop_last=True, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=NUM_GRAPHS_PER_BATCH,drop_last=True, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=NUM_GRAPHS_PER_BATCH,drop_last=True, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVXVvkLTWXK4"
      },
      "source": [
        "Building the GNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6cW2dmJWXK4",
        "outputId": "788156a1-b878-4b85-881f-b31e0766c888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (initial_conv): GCNConv(2, 128)\n",
            "  (conv1): GCNConv(128, 128)\n",
            "  (conv2): GCNConv(128, 128)\n",
            "  (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (lin3): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (act1): ReLU()\n",
            "  (act2): ReLU()\n",
            ")\n",
            "Number of parameters:  82945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.nn import Linear, Dropout\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool, TopKPooling\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "embedding_size = 128\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        # Init parent\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # GCN layers\n",
        "        self.initial_conv = GCNConv(dataset.num_features, embedding_size) #to  translate our node features into the size of the embedding\n",
        "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
        "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
        "        # pooling layer\n",
        "        #self.pool = TopKPooling(embedding_size, ratio=0.8)\n",
        "        #dropout layer\n",
        "        #self.dropout = Dropout(p=0.2)\n",
        "\n",
        "        # Output layer\n",
        "        self.lin1 = Linear(embedding_size*2, 128) # linear output layer ensures that we get a continuous unbounded output value. It input is the flattened vector (embedding size *2) from the pooling layer (mean and max)\n",
        "        self.lin2 = Linear(128, 128)\n",
        "        self.lin3 = Linear(128, 1)\n",
        "\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        self.act2 = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x, edge_index, batch_index):\n",
        "        # First Conv layer\n",
        "        hidden = self.initial_conv(x, edge_index)\n",
        "        hidden = F.relu(hidden)\n",
        "\n",
        "        # Other Conv layers\n",
        "        hidden = self.conv1(hidden, edge_index)\n",
        "        hidden = F.relu(hidden)\n",
        "\n",
        "        hidden = self.conv2(hidden, edge_index)\n",
        "        hidden = F.relu(hidden)\n",
        "        #hidden = self.dropout(hidden)\n",
        "        # Global Pooling (stack different aggregations)\n",
        "        hidden = torch.cat([gmp(hidden, batch_index),\n",
        "                            gap(hidden, batch_index)], dim=1)\n",
        "        # Apply a final (linear) classifier.\n",
        "        out = self.lin1(hidden)\n",
        "        out = self.act1(out)\n",
        "        out = self.lin2(out)\n",
        "        out = self.act2(out)\n",
        "        #out = F.dropout(out, p=0.5, training=self.training)\n",
        "        out = self.lin3(out)\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        # return out, hidden\n",
        "        return out\n",
        "\n",
        "model = GCN()\n",
        "print(model)\n",
        "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbHn1aMOWXK5"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    loss_all = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.x.float(), data.edge_index, data.batch)\n",
        "        label = data.y.to(device)\n",
        "        #loss = torch.sqrt(loss_fn(output, label))\n",
        "        loss = loss_fn(output.squeeze(), label.float())\n",
        "        loss.backward()\n",
        "        loss_all += data.num_graphs * loss.item()\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMcuNPKKWXK5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "\n",
        "            data = data.to(device)\n",
        "            # pred = model(data.x.float(), data.edge_index, data.batch).detach().cpu().numpy()\n",
        "            pred = model(data.x.float(), data.edge_index, data.batch)\n",
        "            label_true = data.y.to(device)\n",
        "            label = data.y.detach().cpu().numpy()\n",
        "            # predictions.append(pred)\n",
        "            # labels.append(label)\n",
        "            predictions.append(np.rint(pred.cpu().detach().numpy()))\n",
        "            labels.append(label)\n",
        "            loss = loss_fn(pred.squeeze(), label_true.float())\n",
        "    # predictions = np.hstack(predictions)\n",
        "    # labels = np.hstack(labels)\n",
        "    predictions = np.concatenate(predictions).ravel()\n",
        "    labels = np.concatenate(labels).ravel()\n",
        "\n",
        "    # print(predictions)\n",
        "    # print(labels)\n",
        "    return accuracy_score(labels, predictions), loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiguqJdGWXK5"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEghBKG_WXK6",
        "outputId": "1f3c089c-63c1-430e-cfe0-50300e439342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train Loss 0.7138057926722935 | Train Accuracy0.699951171875 | Validation Accuracy0.7265625 | Validation loss0.6457016468048096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n",
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss 0.5820643615722656 | Train Accuracy0.697265625 | Validation Accuracy0.6953125 | Validation loss0.5481016039848328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n",
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Train Loss 0.5687667011079334 | Train Accuracy0.691162109375 | Validation Accuracy0.73046875 | Validation loss0.5604127645492554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n",
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Train Loss 0.5672528875441778 | Train Accuracy0.7119140625 | Validation Accuracy0.71875 | Validation loss0.587308406829834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n",
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | Train Loss 0.5643009149460565 | Train Accuracy0.703369140625 | Validation Accuracy0.7109375 | Validation loss0.5838343501091003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n",
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | Train Loss 0.5614966110956101 | Train Accuracy0.700439453125 | Validation Accuracy0.720703125 | Validation loss0.5607606768608093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n",
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 | Train Loss 0.5607733190627325 | Train Accuracy0.701171875 | Validation Accuracy0.697265625 | Validation loss0.599475622177124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n",
            "<ipython-input-19-2a3d370dc5a0>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(os.path.join(self.processed_dir,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 | Train Loss 0.5630459376743862 | Train Accuracy0.7001953125 | Validation Accuracy0.69140625 | Validation loss0.5808665752410889\n",
            "Early stopping due to no improvement.\n",
            "Finishing training with best val loss: 0.5481016039848328\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GCN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "print(\"Starting training...\")\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_acc_list= []\n",
        "train_acc_list= []\n",
        "best_loss = 1000\n",
        "early_stopping_counter = 0\n",
        "for epoch in range(200):\n",
        "    if early_stopping_counter <=  10: # = x * 5\n",
        "        loss = train()\n",
        "        train_losses.append(loss)\n",
        "        train_acc, train_loss = evaluate(train_loader)\n",
        "        #val_acc = evaluate(val_loader)\n",
        "        val_acc, val_loss = evaluate(val_loader)\n",
        "        val_losses.append(val_loss)\n",
        "        val_acc_list.append(val_acc)\n",
        "        train_acc_list.append(train_acc)\n",
        "\n",
        "        if float(val_loss) < best_loss:\n",
        "            best_loss = val_loss\n",
        "            # Save the currently best model\n",
        "            early_stopping_counter = 0\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "        print(f\"Epoch {epoch} | Train Loss {loss} | Train Accuracy{train_acc} | Validation Accuracy{val_acc} | Validation loss{val_loss}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Early stopping due to no improvement.\")\n",
        "        break\n",
        "print(f\"Finishing training with best val loss: {best_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtEutGqyWXK6"
      },
      "source": [
        "Plotting the learning curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZemeuyCWXK7"
      },
      "source": [
        "Printing out the performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-BENpR5WXK7"
      },
      "outputs": [],
      "source": [
        "NUM_GRAPHS_PER_BATCH_1 = 4835\n",
        "test_loader_all = DataLoader(test_dataset, batch_size=NUM_GRAPHS_PER_BATCH_1,drop_last=True, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZtnkeOWWXK7",
        "outputId": "e074f9a5-78b6-4b1e-d7bd-5cbd8ab0a74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Confusion matrix: \n",
            " [[1620  844]\n",
            " [ 461 1910]]\n",
            "\n",
            " Accuracy: 0.7300930713547052\n",
            "\n",
            " Precision: 0.6935366739288308\n",
            "\n",
            " Recall: 0.8055672711935892\n",
            "\n",
            " F1 Score: 0.7453658536585365\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_real</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.4110952913761139]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.6756953597068787]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[0.11998370289802551]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[0.7369117140769958]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[0.13293148577213287]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4830</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.12243560701608658]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4831</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.8020007014274597]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4832</th>\n",
              "      <td>0</td>\n",
              "      <td>[0.5188013911247253]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4833</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.6873726844787598]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4834</th>\n",
              "      <td>0</td>\n",
              "      <td>[0.218715101480484]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4835 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      y_real                 y_pred\n",
              "0          1   [0.4110952913761139]\n",
              "1          1   [0.6756953597068787]\n",
              "2          0  [0.11998370289802551]\n",
              "3          0   [0.7369117140769958]\n",
              "4          0  [0.13293148577213287]\n",
              "...      ...                    ...\n",
              "4830       1  [0.12243560701608658]\n",
              "4831       1   [0.8020007014274597]\n",
              "4832       0   [0.5188013911247253]\n",
              "4833       1   [0.6873726844787598]\n",
              "4834       0    [0.218715101480484]\n",
              "\n",
              "[4835 rows x 2 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Analyze the results for all graphs\n",
        "test_batch = next(iter(test_loader_all))\n",
        "with torch.no_grad():\n",
        "    test_batch.to(device)\n",
        "    pred = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch)\n",
        "    accuracy= accuracy_score(test_batch.y, np.rint(pred))\n",
        "    precision= precision_score(test_batch.y, np.rint(pred), zero_division=1)\n",
        "    recall= recall_score(test_batch.y, np.rint(pred), zero_division=1)\n",
        "    df = pd.DataFrame()\n",
        "    df[\"y_real\"] = test_batch.y.tolist()\n",
        "    df[\"y_pred\"] = pred.tolist()\n",
        "    print(f\"\\n Confusion matrix: \\n {confusion_matrix(test_batch.y, np.rint(pred))}\")\n",
        "    print(f\"\\n Accuracy: {accuracy_score(test_batch.y, np.rint(pred))}\")\n",
        "    print(f\"\\n Precision: {precision_score(test_batch.y, np.rint(pred))}\")\n",
        "    print(f\"\\n Recall: {recall_score(test_batch.y, np.rint(pred))}\")\n",
        "    print(f\"\\n F1 Score: {f1_score(test_batch.y, np.rint(pred))}\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60DPVjWoWXK7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"gnn_model.pth\")\n",
        "\n",
        "# Load model in deployment script\n",
        "model.load_state_dict(torch.load(\"gnn_model.pth\"))\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7DoWWGFPFSa",
        "outputId": "dd6bdbde-de5f-49d4-a249-6154739652d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.41.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.21.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytDsuBeKPk8P",
        "outputId": "6b446443-22af-4838-9821-f3169f14aedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.126.137.109:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LAxMLM5tQoq3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "ed38e45ff0aaff95ccfc69f4fb6b3b80052ffc6235959bf5d9d2fb5b2218aec2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "orig_nbformat": 2,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}